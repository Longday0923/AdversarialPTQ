
Job information
#-------------------------------------------------------------------
SLURM_SUBMIT_HOST    gl-login3.arc-ts.umich.edu
SLURM_JOB_ACCOUNT    eecs598w23_class
SLURM_JOB_PARTITION  gpu
SLURM_JOB_NAME       AdvPTQ
SLURM_JOBID          50042982
SLURM_NODELIST       gl1011
SLURM_JOB_NUM_NODES  1
SLURM_NTASKS         
SLURM_TASKS_PER_NODE 1
SLURM_CPUS_PER_TASK  8
SLURM_NPROCS         
SLURM_MEM_PER_CPU    
GPU_DEVICE_ORDINAL   0
GPU 0: Tesla V100-PCIE-16GB (UUID: GPU-15de816d-ee7e-2fa3-bbc5-ab6bb0de7e33)
SLURM_SUBMIT_DIR     /home/zhtianyu/AdversarialPTQ

scheduling priority             (-e) 0
pending signals                 (-i) 766930
max memory size         (kbytes, -m) 16777216
open files                      (-n) 131072
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
max user processes              (-u) 766930

Running on gl1011.arc-ts.umich.edu at Thu Mar 30 21:04:39 EDT 2023

Currently Loaded Modules:
  1) python3.9-anaconda/2021.11   2) cuda/11.3.0

Your job output begins below the line
#-------------------------------------------------------------------
python eecs598_pgd.py     --seed 42     --dataset cifar10     --datnorm     --network WideResNet     --trained=/gpfs/accounts/eecs598w23_class_root/eecs598w23_class/shared_data/zhtianyu/models/cifar10/train/model_cifar_wrn.pt     --classes 10     --batch-size 128     --epoch 1     --optimizer Adam     --lr 0.00001     --momentum 0.9     --numbit 8 7 6 5     --w-qmode per_channel_symmetric     --a-qmode per_layer_asymmetric     --lratio 1.0     --margin 5.0     --step 50     --gamma 0.1 \ 
    --numrun 1     --att-type PGD     --att-tar untar     --att-step-size 0.05     --att-num-steps 10     --att-epsilon 0.03
cuda available:  True
cuda avail:  True
{
  "system": {
    "seed": 42,
    "cuda": true,
    "num-workers": 4,
    "pin-memory": true
  },
  "model": {
    "dataset": "cifar10",
    "datnorm": true,
    "network": "WideResNet",
    "trained": "/gpfs/accounts/eecs598w23_class_root/eecs598w23_class/shared_data/zhtianyu/models/cifar10/train/model_cifar_wrn.pt",
    "lossfunc": "cross-entropy",
    "optimizer": "Adam",
    "classes": 10,
    "w-qmode": "per_channel_symmetric",
    "a-qmode": "per_layer_asymmetric"
  },
  "params": {
    "batch-size": 128,
    "epoch": 1,
    "lr": 1e-05,
    "momentum": 0.9,
    "step": 50,
    "gamma": 0.1
  },
  "attack": {
    "numbit": [
      8,
      7,
      6,
      5
    ],
    "lratio": 1.0,
    "margin": 5.0,
    "numrun": 1
  },
  "adv_attack": {
    "type": "PGD",
    "tar": "untar",
    "kwargs": {
      "step_size": 0.05,
      "num_steps": 10,
      "epsilon": 0.03
    }
  }
}
Files already downloaded and verified
Files already downloaded and verified
 : load the dataset - cifar10 (norm: True)
 : load network - WideResNet
 : load loss - cross-entropy / optim - Adam
 : set the store locations
  - model : models/cifar10/eecs598_pgd/model_cifar_wrn.pt
  - result: results/cifar10/eecs598_pgd/model_cifar_wrn.pt
 : store logs to [results/cifar10/eecs598_pgd/model_cifar_wrn.pt/attack_8765_1.0_5.0_wpcs_apla-optimize_1_Adam_1e-05.1.csv]
 : [epoch:Base][valid] [acc: 64.13% / loss: 1.064]
 : [epoch:1][valid] [acc: 53.25% / loss: 1.403]
 : [epoch:1][valid] [acc: 64.35% / loss: 1.062] - [w: per_channel_symmetric, a: per_layer_asymmetric / bits: 8]
 : [epoch:1][valid] [acc: 53.23% / loss: 1.400] - [w: per_channel_symmetric, a: per_layer_asymmetric / bits: 8]
 : [epoch:1][valid] [acc: 62.76% / loss: 1.108] - [w: per_channel_symmetric, a: per_layer_asymmetric / bits: 6]
 : [epoch:1][valid] [acc: 52.39% / loss: 1.440] - [w: per_channel_symmetric, a: per_layer_asymmetric / bits: 6]
 : [epoch:1][valid] [acc: 62.59% / loss: 1.149] - [w: per_channel_symmetric, a: per_layer_asymmetric / bits: 4]
 : [epoch:1][valid] [acc: 55.88% / loss: 1.381] - [w: per_channel_symmetric, a: per_layer_asymmetric / bits: 4]
 : done.
